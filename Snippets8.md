# ğŸ“š ×¡×¤×¨×™×™×ª Code Snippets ×œ×‘×•×˜×™ ×˜×œ×’×¨×

×¡×¤×¨×™×™×” ×©×œ ×§×˜×¢×™ ×§×•×“ ×©×™××•×©×™×™× ××”×¨×™×¤×• ×”× ×•×›×—×™ ×œ××¤×ª×—×™× ×©×‘×•× ×™× ×‘×•×˜×™× ×•×–×¨×™××•×ª ×˜×œ×’×¨×.

---

## Rate Limiting ×¢× Shadow Mode ×•-Admin Bypass

**×œ××” ×–×” ×©×™××•×©×™:** ××’×‘×™×œ ×§×¦×‘ ×‘×§×©×•×ª ×œ××©×ª××©×™× ×ª×•×š ××ª×Ÿ ×¢×§×™×¤×” ×œ××“××™× ×™×. ××¦×‘ Shadow ×××¤×©×¨ ×œ×‘×“×•×§ ××ª ×”×”×’×‘×œ×•×ª ×‘×œ×™ ×œ×—×¡×•× ×‘×××ª â€“ ××•×©×œ× ×œ×˜×¡×˜×™× ×‘×¤×¨×•×“×§×©×Ÿ.

```python
from limits import RateLimitItemPerMinute
from limits.storage import RedisStorage
from limits.strategies import MovingWindowRateLimiter
from functools import wraps
import os

# ×”×’×“×¨×ª ××’×‘×œ×•×ª
LIMITS = {
    "default": RateLimitItemPerMinute(20),
    "sensitive": RateLimitItemPerMinute(5),
}

# Redis ××• fallback ×œ××¦×‘ ×œ×œ× ×”×’×‘×œ×”
_storage = RedisStorage(os.getenv("REDIS_URL")) if os.getenv("REDIS_URL") else None
_limiter = MovingWindowRateLimiter(_storage) if _storage else None

def rate_limit(scope: str, limit_name: str = "default", bypass_admins: bool = True):
    def decorator(func):
        @wraps(func)
        async def wrapper(update, context, *args, **kwargs):
            user_id = update.effective_user.id if update.effective_user else 0

            # ×¢×§×™×¤×” ×œ××“××™× ×™×
            if bypass_admins and user_id in {int(x) for x in os.getenv("ADMIN_USER_IDS", "").split(",") if x.isdigit()}:
                return await func(update, context, *args, **kwargs)

            # ×‘×“×™×§×ª ×”×’×‘×œ×” (fail-open ×× Redis ×œ× ×–××™×Ÿ)
            if _limiter is None:
                return await func(update, context, *args, **kwargs)

            key = f"tg:{scope}:{user_id}"
            shadow_mode = os.getenv("RATE_LIMIT_SHADOW_MODE", "false").lower() == "true"

            if not _limiter.hit(LIMITS[limit_name], key):
                if shadow_mode:
                    pass  # ×¨×§ ×œ×•×’, ×œ× ×—×•×¡×
                else:
                    await update.message.reply_text("â° ×©×œ×—×ª ×™×•×ª×¨ ××“×™ ×‘×§×©×•×ª. × ×¡×” ×©×•×‘ ×‘×¢×•×“ ×“×§×”.")
                    return

            return await func(update, context, *args, **kwargs)
        return wrapper
    return decorator

# ×©×™××•×©:
@rate_limit("image_generation", "sensitive")
async def generate_image(update, context):
    ...
```

---

## TTL ×“×™× ××™ ×œ×¤×™ ×¡×•×’ ×ª×•×›×Ÿ ×•×§×•× ×˜×§×¡×˜

**×œ××” ×–×” ×©×™××•×©×™:** ×‘××§×•× TTL ×§×‘×•×¢ ×œ×›×œ ×”Cache, ××ª××™× ××ª ×–××Ÿ ×”×©××™×¨×” ×œ×¤×™ ×¡×•×’ ×”×ª×•×›×Ÿ â€“ ×ª×•×›×Ÿ ×©××©×ª× ×” ×”×¨×‘×” (×”×’×“×¨×•×ª) ××§×‘×œ TTL ×§×¦×¨, ×ª×•×›×Ÿ ×™×¦×™×‘ (×§×‘×¦×™×) ××§×‘×œ TTL ××¨×•×š.

```python
class DynamicTTL:
    """TTL ×“×™× ××™ ×œ×¤×™ ×¡×•×’ ×ª×•×›×Ÿ"""

    BASE_TTL = {
        "user_stats": 600,        # 10 ×“×§×•×ª
        "file_content": 3600,     # ×©×¢×”
        "file_list": 300,         # 5 ×“×§×•×ª
        "search_results": 180,    # 3 ×“×§×•×ª
        "settings": 60,           # ×“×§×”
    }

    @classmethod
    def calculate_ttl(cls, content_type: str, context: dict = None) -> int:
        ctx = context or {}
        base_ttl = cls.BASE_TTL.get(content_type, 300)

        # ××•×¢×“×¤×™× â€“ TTL ××¨×•×š ×™×•×ª×¨
        if ctx.get("is_favorite"):
            base_ttl = int(base_ttl * 1.5)

        # ×ª×•×›×Ÿ ×©×”×©×ª× ×” ×œ××—×¨×•× ×” â€“ TTL ×§×¦×¨ ×™×•×ª×¨
        if ctx.get("last_modified_hours_ago", 24) < 1:
            base_ttl = int(base_ttl * 0.5)

        # ××©×ª××©×™ ×¤×¨×™××™×•× ××¢×“×™×¤×™× ×ª×•×›×Ÿ ×¢×“×›× ×™
        if ctx.get("user_tier") == "premium":
            base_ttl = int(base_ttl * 0.7)

        return max(60, min(base_ttl, 7200))  # ×‘×™×Ÿ ×“×§×” ×œ×©×¢×ª×™×™×

# ×©×™××•×©:
ttl = DynamicTTL.calculate_ttl("file_content", {"is_favorite": True})
cache.set(key, value, ex=ttl)
```

---

## TTL ×œ×¤×™ ×©×¢×•×ª ×¤×¢×™×œ×•×ª (Activity-Based)

**×œ××” ×–×” ×©×™××•×©×™:** ×‘×©×¢×•×ª ×©×™× (9-18) ×”Cache ××ª×¨×¢× ×Ÿ ××”×¨ ×™×•×ª×¨ ×›×™ ×™×© ×™×•×ª×¨ ××©×ª××©×™× ×¤×¢×™×œ×™×. ×‘×œ×™×œ×” â€“ TTL ××¨×•×š ×›×™ ×¤×—×•×ª ×¤×¢×™×œ×•×ª.

```python
import random
from datetime import datetime

class ActivityBasedTTL:
    """×”×ª×××ª TTL ×œ×¤×™ ×©×¢×•×ª ×¤×¢×™×œ×•×ª"""

    @classmethod
    def get_activity_multiplier(cls) -> float:
        hour = datetime.now().hour
        if 9 <= hour < 18:      # ×©×¢×•×ª ×©×™× â€“ ×§×¦×¨ ×™×•×ª×¨
            return 0.7
        if 18 <= hour < 23:     # ×¢×¨×‘ â€“ ×‘×™× ×•× ×™
            return 1.0
        return 1.5              # ×œ×™×œ×” â€“ ××¨×•×š ×™×•×ª×¨

    @classmethod
    def adjust_ttl(cls, base_ttl: int) -> int:
        ttl = int(base_ttl * cls.get_activity_multiplier())

        # ×”×•×¡×£ jitter ×œ×× ×™×¢×ª thundering herd
        jitter = max(1, ttl // 10)
        ttl += random.randint(-jitter, jitter)

        return max(60, min(ttl, 7200))

# ×©×™××•×©:
base_ttl = 300  # 5 ×“×§×•×ª
actual_ttl = ActivityBasedTTL.adjust_ttl(base_ttl)
```

---

## ×‘× ×™×™×ª ××¤×ª×— Cache ×‘×˜×•×—

**×œ××” ×–×” ×©×™××•×©×™:** ××•× ×¢ ××¤×ª×—×•×ª ×©×‘×•×¨×™× ××ª×•×•×™× ××™×•×—×“×™×, ××’×‘×™×œ ××•×¨×š ××•×˜×•××˜×™×ª ×¢× hash, ×•××¡× ×Ÿ ×¢×¨×›×™× ×¨×™×§×™×.

```python
from hashlib import sha256

def build_cache_key(*parts) -> str:
    """×‘× ×™×™×ª ××¤×ª×— cache ×™×¢×™×œ ×•××•×‘× ×”"""
    # ×¡×™× ×•×Ÿ ×—×œ×§×™× ×¨×™×§×™×
    clean_parts = [str(p) for p in parts if p not in (None, "")]
    key = ":".join(clean_parts)

    # ×ª×•×•×™× ×‘×˜×•×—×™× ×‘×œ×‘×“
    key = key.replace(" ", "_").replace("/", "-")

    # ×”×’×‘×œ×ª ××•×¨×š ×¢× hash
    if len(key) > 200:
        key_hash = sha256(key.encode()).hexdigest()[:8]
        key = f"{key[:150]}:{key_hash}"

    return key

# ×©×™××•×©:
key = build_cache_key("user", user_id, "files", "list")
# => "user:123:files:list"

key = build_cache_key("search", user_id, very_long_query)
# => "search:123:the_query_truncated...:a1b2c3d4"
```

---

## ×¢×‘×•×“×ª Batch ×¢× ××¢×§×‘ ×”×ª×§×“××•×ª

**×œ××” ×–×” ×©×™××•×©×™:** ×¢×™×‘×•×“ ××§×‘×™×œ×™ ×©×œ ××¡×¤×¨ ×§×‘×¦×™×/×¤×¨×™×˜×™× ×¢× ××¢×§×‘ ××—×¨ ×”×ª×§×“××•×ª, ××¦×‘ (pending/running/completed), ×•×˜×™×¤×•×œ ×‘×©×’×™××•×ª ×œ×›×œ ×¤×¨×™×˜ ×‘× ×¤×¨×“.

```python
from dataclasses import dataclass, field
from concurrent.futures import ThreadPoolExecutor, as_completed
from typing import Dict, List, Any, Callable
import time

@dataclass
class BatchJob:
    job_id: str
    user_id: int
    files: List[str]
    status: str = "pending"  # pending, running, completed, failed
    progress: int = 0
    total: int = 0
    results: Dict[str, Any] = field(default_factory=dict)

    def __post_init__(self):
        self.total = len(self.files)

async def process_batch(job: BatchJob, operation_func: Callable):
    """×¢×™×‘×•×“ batch ×¢× ThreadPoolExecutor"""
    job.status = "running"

    with ThreadPoolExecutor(max_workers=3) as executor:
        future_to_file = {
            executor.submit(operation_func, job.user_id, f): f
            for f in job.files
        }

        for future in as_completed(future_to_file):
            file_name = future_to_file[future]
            try:
                result = future.result()
                job.results[file_name] = {"success": True, "result": result}
            except Exception as e:
                job.results[file_name] = {"success": False, "error": str(e)}

            job.progress += 1

    failed = sum(1 for r in job.results.values() if not r.get("success"))
    job.status = "completed" if failed == 0 else "failed"
    return job

# ×©×™××•×©:
job = BatchJob("batch_1", user_id=123, files=["a.py", "b.py", "c.py"])
result = await process_batch(job, validate_file)
print(f"×”×•×©×œ××•: {job.progress}/{job.total}")
```

---

## ××™××•×ª ×—×ª×™××ª GitHub Webhook

**×œ××” ×–×” ×©×™××•×©×™:** ××‘×˜×™×— ×©×”Webhook ×”×’×™×¢ ×‘×××ª ×GitHub ×•×œ× ×××§×•×¨ ×–×“×•× ×™. ×—×•×‘×” ×œ×›×œ ×‘×•×˜ ×©××§×‘×œ webhooks.

```python
import hmac
import hashlib
import os

def verify_github_signature(payload_body: bytes, signature: str) -> bool:
    """××™××•×ª ×—×ª×™××ª GitHub Webhook"""
    secret = os.getenv("GITHUB_WEBHOOK_SECRET", "")

    if not secret:
        return False

    if not signature or not signature.startswith("sha256="):
        return False

    expected = hmac.new(
        secret.encode(),
        payload_body,
        hashlib.sha256
    ).hexdigest()

    received = signature[7:]  # ×”×¡×¨ "sha256=" prefix

    return hmac.compare_digest(expected, received)

# ×©×™××•×© ×‘Flask:
@app.route("/webhook/github", methods=["POST"])
def handle_webhook():
    signature = request.headers.get("X-Hub-Signature-256", "")

    if not verify_github_signature(request.data, signature):
        return {"error": "Invalid signature"}, 401

    event_type = request.headers.get("X-GitHub-Event")
    # ×”××©×š ×˜×™×¤×•×œ...
```

---

## ×—×™×‘×•×¨ MongoDB Singleton ×¢× × ×™×§×•×™ ××•×˜×•××˜×™

**×œ××” ×–×” ×©×™××•×©×™:** ××•× ×¢ ×™×¦×™×¨×ª ×—×™×‘×•×¨×™× ××¨×•×‘×™× ×œ××¡×“ ×”× ×ª×•× ×™×, ×× ×”×œ ×¡×’×™×¨×” × ×§×™×™×” ×‘×™×¦×™××”, ×•×ª×•××š ×‘×©×™××•×© ×—×•×–×¨ ×‘×—×™×‘×•×¨ ×§×™×™×.

```python
import atexit
from datetime import timezone
from pymongo import MongoClient

_client = None
_owns_client = False

def get_mongo_client(mongodb_uri: str):
    """Singleton ×œ×—×™×‘×•×¨ MongoDB"""
    global _client, _owns_client

    if _client is not None:
        return _client

    # × ×¡×” ×œ××—×–×¨ ×—×™×‘×•×¨ ×§×™×™×
    try:
        from database import db
        existing = getattr(db, "client", None)
        if existing:
            _client = existing
            _owns_client = False
            return _client
    except Exception:
        pass

    # ×™×¦×™×¨×ª ×—×™×‘×•×¨ ×—×“×©
    _client = MongoClient(mongodb_uri, tz_aware=True, tzinfo=timezone.utc)
    _owns_client = True
    return _client

def close_mongo_client():
    """×¡×’×™×¨×” ×‘×˜×•×—×” ×‘×™×¦×™××”"""
    global _client
    if _client and _owns_client:
        _client.close()
    _client = None

# ×¨×™×©×•× ×œ×¡×’×™×¨×” ××•×˜×•××˜×™×ª
atexit.register(close_mongo_client)
```

---

## ××¢×§×‘ ×¤×¢×™×œ×•×ª ×¢× Dual-Path (DB + Metrics)

**×œ××” ×–×” ×©×™××•×©×™:** ×’× ×× ××¡×“ ×”× ×ª×•× ×™× ×œ× ×–××™×Ÿ, ×”×¤×¢×™×œ×•×ª ×¢×“×™×™×Ÿ × ×¨×©××ª ×‘××˜×¨×™×§×•×ª. ××‘×˜×™×— ×©×œ× ×ª××‘×“ ××™×“×¢ ×¢×œ ×¤×¢×™×œ×•×ª ××©×ª××©×™×.

```python
from datetime import datetime, timezone

class ActivityReporter:
    def __init__(self, db, note_active_user_func=None):
        self.db = db
        self.note_active_user = note_active_user_func or (lambda x: None)

    def report_activity(self, user_id: int, service_id: str):
        """×“×™×•×•×— ×¤×¢×™×œ×•×ª ×¢× fallback ×œ××˜×¨×™×§×•×ª"""
        now = datetime.now(timezone.utc)

        # × ×¡×” DB ×§×•×“×
        try:
            self.db.user_interactions.update_one(
                {"service_id": service_id, "user_id": user_id},
                {
                    "$set": {"last_interaction": now},
                    "$inc": {"interaction_count": 1},
                    "$setOnInsert": {"created_at": now}
                },
                upsert=True
            )
        except Exception:
            pass  # DB × ×›×©×œ â€“ × ××©×™×š ×œ××˜×¨×™×§×•×ª

        # ×ª××™×“ ×¢×“×›×Ÿ ××˜×¨×™×§×•×ª (×’× ×× DB ×”×¦×œ×™×—)
        try:
            self.note_active_user(user_id)
        except Exception:
            pass

# ×©×™××•×©:
reporter = ActivityReporter(db, note_active_user=prometheus_gauge.set)
reporter.report_activity(user_id=123, service_id="my_bot")
```

---

## ×—×™×¤×•×© Fuzzy ×¢× Fallback

**×œ××” ×–×” ×©×™××•×©×™:** ×—×™×¤×•×© ×—×›× ×©××•×¦× ×”×ª×××•×ª ×’× ×¢× ×©×’×™××•×ª ×›×ª×™×‘. ×× rapidfuzz ×œ× ××•×ª×§×Ÿ â€“ × ×•×¤×œ ×œ×—×™×¤×•×© ×¤×©×•×˜ ×™×•×ª×¨.

```python
from typing import List, Tuple

# × ×¡×” rapidfuzz (××”×™×¨), ××—×¨×ª fallback
try:
    from rapidfuzz import fuzz, process
    HAS_FUZZY = True
except ImportError:
    HAS_FUZZY = False

def fuzzy_search(query: str, choices: List[str], limit: int = 5, min_score: int = 60) -> List[Tuple[str, int]]:
    """×—×™×¤×•×© fuzzy ×¢× fallback ×œ×—×™×¤×•×© ×¤×©×•×˜"""
    if not query or not choices:
        return []

    if HAS_FUZZY:
        results = process.extract(query, choices, scorer=fuzz.partial_ratio, limit=limit)
        return [(match, score) for match, score, _ in results if score >= min_score]

    # Fallback ×¤×©×•×˜
    query_lower = query.lower()
    scored = []
    for choice in choices:
        choice_lower = choice.lower()
        if query_lower in choice_lower or choice_lower in query_lower:
            # ×¦×™×•×Ÿ ×œ×¤×™ ××—×•×– ×—×¤×™×¤×”
            score = int(100 * min(len(query), len(choice)) / max(len(query), len(choice)))
            scored.append((choice, score))

    scored.sort(key=lambda x: x[1], reverse=True)
    return [(c, s) for c, s in scored[:limit] if s >= min_score]

# ×©×™××•×©:
files = ["main.py", "utils.py", "helpers.py", "test_main.py"]
matches = fuzzy_search("main", files)
# => [("main.py", 100), ("test_main.py", 80)]
```

---

## ×§×™×“×•×“ Callback Data ×¢× ×˜×•×§× ×™× (××’×‘×œ×ª 64 ×‘×™×™×˜)

**×œ××” ×–×” ×©×™××•×©×™:** ×˜×œ×’×¨× ××’×‘×™×œ callback_data ×œ-64 ×‘×™×™×˜×™×. ×›×©×©××•×ª ×§×‘×¦×™× ××¨×•×›×™×, × ×©×ª××© ×‘×˜×•×§× ×™× ×§×¦×¨×™× ×‘××§×•× ×”×©× ×”××œ×.

```python
import secrets

def get_or_create_token(context, file_name: str) -> str:
    """×™×¦×™×¨×ª ×˜×•×§×Ÿ ×§×¦×¨ ×œ×©× ×§×•×‘×¥ ××¨×•×š"""
    tokens = context.user_data.setdefault('name_by_tok', {})
    reverse = context.user_data.setdefault('tok_by_name', {})

    # ×× ×›×‘×¨ ×™×© ×˜×•×§×Ÿ â€“ ×”×—×–×¨ ××•×ª×•
    if file_name in reverse:
        return reverse[file_name]

    # ×¦×•×¨ ×˜×•×§×Ÿ ×—×“×©
    tok = secrets.token_hex(4)  # 8 ×ª×•×•×™×
    while tok in tokens:
        tok = secrets.token_hex(4)

    tokens[tok] = file_name
    reverse[file_name] = tok
    return tok

def resolve_token(context, callback_suffix: str) -> str:
    """×¤×¢× ×•×— ×˜×•×§×Ÿ ×—×–×¨×” ×œ×©× ×§×•×‘×¥"""
    if callback_suffix.startswith('tok:'):
        token = callback_suffix.split(':', 1)[1]
        return context.user_data.get('name_by_tok', {}).get(token, callback_suffix)
    return callback_suffix

def make_safe_callback(context, action: str, file_name: str) -> str:
    """×™×¦×™×¨×ª callback_data ×‘×˜×•×—"""
    callback = f"{action}{file_name}"

    if len(callback.encode('utf-8')) <= 64:
        return callback

    token = get_or_create_token(context, file_name)
    return f"{action}tok:{token}"

# ×©×™××•×©:
callback_data = make_safe_callback(context, "show_", very_long_filename)
# => "show_tok:a1b2c3d4" ×‘××§×•× "show_very_long_filename_that_exceeds_limit"

# ×‘handler:
file_name = resolve_token(context, query.data.replace("show_", ""))
```

---

## ×“×§×•×¨×˜×•×¨ ×œ××“×™×“×ª ×‘×™×¦×•×¢×™ ×¤×¢×•×œ×•×ª DB

**×œ××” ×–×” ×©×™××•×©×™:** ××•×“×“ ××•×˜×•××˜×™×ª ××ª ×–××Ÿ ×›×œ ×¤×¢×•×œ×ª ××¡×“ × ×ª×•× ×™× ×•××“×•×•×— ×œ××˜×¨×™×§×•×ª. ××–×”×” ×¤×¢×•×œ×•×ª ××™×˜×™×•×ª ×‘×§×œ×•×ª.

```python
import time
from functools import wraps

def instrument_db(operation_name: str):
    """×“×§×•×¨×˜×•×¨ ×œ××¢×§×‘ ×‘×™×¦×•×¢×™ DB"""
    def decorator(func):
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            start = time.perf_counter()
            status = "ok"

            try:
                result = func(self, *args, **kwargs)
                if isinstance(result, bool):
                    status = "ok" if result else "fail"
                return result
            except Exception:
                status = "error"
                raise
            finally:
                duration = time.perf_counter() - start
                try:
                    record_db_operation(operation_name, duration, status=status)
                except Exception:
                    pass

        return wrapper
    return decorator

# ×©×™××•×©:
class Repository:
    @instrument_db("db.save_snippet")
    def save_snippet(self, user_id: int, content: str):
        return self.collection.insert_one({"user_id": user_id, "content": content})

    @instrument_db("db.get_user_files")
    def get_user_files(self, user_id: int):
        return list(self.collection.find({"user_id": user_id}))
```

---

## ×“×§×•×¨×˜×•×¨×™× ××©×•×¨×©×¨×™× ×œ×”×¨×©××•×ª

**×œ××” ×–×” ×©×™××•×©×™:** ×©×™×œ×•×‘ ××¡×¤×¨ ×‘×“×™×§×•×ª ×”×¨×©××” ×‘×“×§×•×¨×˜×•×¨ ××—×“ â€“ ×¨×©×™××ª ×¦'××˜×™× ××•×¨×©×™×, ×‘×“×™×§×ª ××“××™×Ÿ, ×•×”×’×‘×œ×ª ×§×¦×‘. ×§×•×“ × ×§×™ ×•×§×¨×™×.

```python
from functools import wraps

def admin_required(func):
    """×‘×“×™×§×” ×©×”××©×ª××© ××“××™×Ÿ"""
    @wraps(func)
    async def wrapper(update, context, *args, **kwargs):
        user_id = update.effective_user.id if update.effective_user else 0
        admin_ids = {int(x) for x in os.getenv("ADMIN_USER_IDS", "").split(",") if x.isdigit()}

        if user_id not in admin_ids:
            await update.message.reply_text("âŒ ×¤×§×•×“×” ×–×• ×–××™× ×” ×œ×× ×”×œ×™× ×‘×œ×‘×“.")
            return

        return await func(update, context, *args, **kwargs)
    return wrapper

def chat_allowlist_required(func):
    """×‘×“×™×§×” ×©×”×¦'××˜ ×‘×¨×©×™××” ×”××•×¨×©×™×ª"""
    @wraps(func)
    async def wrapper(update, context, *args, **kwargs):
        chat_id = update.effective_chat.id if update.effective_chat else 0
        allowed = {int(x) for x in os.getenv("ALLOWED_CHAT_IDS", "").split(",") if x.lstrip("-").isdigit()}

        if allowed and chat_id not in allowed:
            return  # ×”×ª×¢×œ× ×‘×©×§×˜

        return await func(update, context, *args, **kwargs)
    return wrapper

# ×©×™××•×© â€“ ×©×¨×©×¨×ª ×“×§×•×¨×˜×•×¨×™×:
@chat_allowlist_required
@admin_required
@rate_limit("admin_commands", "sensitive")
async def restart_service(update, context):
    """×¤×§×•×“×ª × ×™×”×•×œ â€“ ×¨×§ ×œ××“××™× ×™×, ×¨×§ ×‘×¦'××˜×™× ××•×¨×©×™×"""
    ...
```

---

## ×ª×–××•×Ÿ ×ª×–×›×•×¨×•×ª ×¢× Job Queue

**×œ××” ×–×” ×©×™××•×©×™:** ×©×™××•×© ×‘-job_queue ×©×œ python-telegram-bot ×œ×ª×–××•×Ÿ ××©×™××•×ª ×¢×ª×™×“×™×•×ª, ×¢× ×˜×¢×™× ×ª ×ª×–×›×•×¨×•×ª ×§×™×™××•×ª ×‘×”×¤×¢×œ×” ××—×“×©.

```python
from datetime import datetime, timezone
from telegram.ext import Application

class ReminderScheduler:
    def __init__(self, application: Application, db):
        self.app = application
        self.db = db
        self.job_queue = application.job_queue

    async def start(self):
        """×˜×¢×™× ×ª ×ª×–×›×•×¨×•×ª ×§×™×™××•×ª"""
        reminders = self.db.get_pending_reminders()
        for reminder in reminders:
            await self.schedule_reminder(reminder)

        # ×‘×“×™×§×ª ×ª×–×›×•×¨×•×ª ×—×•×–×¨×•×ª ×›×œ ×©×¢×”
        self.job_queue.run_repeating(
            self._check_recurring,
            interval=3600,
            first=10,
            name="recurring_check"
        )

    async def schedule_reminder(self, reminder: dict) -> bool:
        rid = reminder["reminder_id"]
        when = reminder["remind_at"]
        user_id = reminder["user_id"]
        name = f"reminder_{rid}"

        # ×‘×˜×œ job ×§×™×™× ×× ×™×©
        for job in self.job_queue.get_jobs_by_name(name):
            job.schedule_removal()

        if when <= datetime.now(timezone.utc):
            # ×©×œ×— ××™×“
            await self._send_reminder(reminder)
        else:
            # ×ª×–××Ÿ ×œ×¢×ª×™×“
            self.job_queue.run_once(
                self._send_job,
                when=when,
                name=name,
                data=reminder,
                chat_id=user_id
            )
        return True

    async def _send_job(self, context):
        await self._send_reminder(context.job.data)

    async def _send_reminder(self, reminder: dict):
        from telegram import InlineKeyboardButton, InlineKeyboardMarkup

        kb = [[
            InlineKeyboardButton("âœ… ×‘×•×¦×¢", callback_data=f"rem_done_{reminder['reminder_id']}"),
            InlineKeyboardButton("â° ×“×—×”", callback_data=f"rem_snooze_{reminder['reminder_id']}")
        ]]

        await self.app.bot.send_message(
            chat_id=reminder["user_id"],
            text=f"â° **×ª×–×›×•×¨×ª!**\n\nğŸ“Œ {reminder['title']}",
            parse_mode="Markdown",
            reply_markup=InlineKeyboardMarkup(kb)
        )

# ×©×™××•×©:
def setup_reminders(application):
    scheduler = ReminderScheduler(application, db)
    application.job_queue.run_once(
        lambda ctx: ctx.application.create_task(scheduler.start()),
        when=1
    )
```

---

## ×™×™×‘×•× ××•×¤×¦×™×•× ×œ×™ ×¢× Fallback

**×œ××” ×–×” ×©×™××•×©×™:** ×××¤×©×¨ ×œ×§×•×“ ×œ×¨×•×¥ ×’× ×‘×œ×™ ×ª×œ×•×™×•×ª ××•×¤×¦×™×•× ×œ×™×•×ª. ×©×™××•×©×™ ×œ×˜×¡×˜×™× ×•×œ×¡×‘×™×‘×•×ª ××™× ×™××œ×™×•×ª.

```python
# ×“×¤×•×¡ 1: ×™×™×‘×•× ×¢× fallback ×œNone
try:
    import aiohttp
except ImportError:
    aiohttp = None

# ×©×™××•×© ×‘×˜×•×—
if aiohttp is not None:
    async with aiohttp.ClientSession() as session:
        ...

# ×“×¤×•×¡ 2: fallback ×œ×¤×•× ×§×¦×™×” ×¨×™×§×”
try:
    from metrics import record_event
except ImportError:
    def record_event(*args, **kwargs):
        pass  # ×œ× ×¢×•×©×” ×›×œ×•×

# ×“×¤×•×¡ 3: fallback ×œ×“×§×•×¨×˜×•×¨ ×¨×™×§
try:
    from cache_manager import cached
except ImportError:
    def cached(expire_seconds=300, key_prefix="default"):
        def decorator(func):
            return func  # ××—×–×™×¨ ××ª ×”×¤×•× ×§×¦×™×” ×›××• ×©×”×™×
        return decorator

# ×“×¤×•×¡ 4: fallback ×œ××—×œ×§×” ××™× ×™××œ×™×ª
try:
    from cache_manager import cache
except ImportError:
    class cache:  # NullCache
        @staticmethod
        def get(key): return None
        @staticmethod
        def set(key, value, ex=None): pass
        @staticmethod
        def delete(key): pass
```

---

## × ×™×§×•×™ ×¡×¤×¨×™×™×ª Temp ×‘×˜×•×—

**×œ××” ×–×” ×©×™××•×©×™:** ××•× ×¢ ××—×™×§×” ×‘×˜×¢×•×ª ×©×œ ×¡×¤×¨×™×•×ª ×—×©×•×‘×•×ª. ××•×•×“× ×©×× ×—× ×• ××•×—×§×™× ×¨×§ ××ª×•×š /tmp ×•××˜×¤×œ ×‘sharing violations.

```python
import os
import shutil

def safe_cleanup(path: str) -> bool:
    """× ×™×§×•×™ ×¡×¤×¨×™×™×” ×¢× ×‘×“×™×§×•×ª ×‘×˜×™×—×•×ª"""
    try:
        # ×•×™×“×•× ×©×”× ×ª×™×‘ ×”×•× ×‘×ª×•×š /tmp
        real_path = os.path.realpath(path)
        if not real_path.startswith("/tmp/"):
            return False

        # ×œ× ××•×—×§×™× ×¡×¤×¨×™×•×ª ×¨××©×™×•×ª
        forbidden = {"/tmp", "/tmp/", "/var", "/home"}
        if real_path.rstrip("/") in forbidden:
            return False

        # ×•×™×“×•× ×©×”×¡×¤×¨×™×™×” ×§×™×™××ª
        if not os.path.exists(real_path):
            return True  # ×›×‘×¨ ×œ× ×§×™×™××ª

        if os.path.isfile(real_path):
            os.remove(real_path)
        else:
            shutil.rmtree(real_path, ignore_errors=True)

        return True

    except PermissionError:
        return False  # ×§×•×‘×¥ ×‘×©×™××•×©
    except Exception:
        return False

# ×©×™××•×©:
temp_dir = "/tmp/bot_processing_123"
# ... ×¢×™×‘×•×“ ...
safe_cleanup(temp_dir)
```

---

## ×¨×™×©×•× ××˜×¨×™×§×•×ª Prometheus ××™×“××¤×•×˜× ×˜×™

**×œ××” ×–×” ×©×™××•×©×™:** ××•× ×¢ ×©×’×™××•×ª ×›×©×”××•×“×•×œ × ×˜×¢×Ÿ ××—×“×© (reload). ××—×–×™×¨ ××˜×¨×™×§×” ×§×™×™××ª ×× ×›×‘×¨ ×¨×©×•××”.

```python
try:
    from prometheus_client import Counter, Histogram, REGISTRY
except ImportError:
    Counter = Histogram = REGISTRY = None

def ensure_metric(name: str, create_fn):
    """×™×¦×™×¨×ª ××˜×¨×™×§×” ××• ×”×—×–×¨×ª ×§×™×™××ª"""
    if REGISTRY is None:
        return None

    # ×‘×“×•×§ ×× ×›×‘×¨ ×§×™×™××ª
    try:
        existing = REGISTRY._names_to_collectors.get(name)
        if existing:
            return existing
    except Exception:
        pass

    # × ×¡×” ×œ×™×¦×•×¨
    try:
        return create_fn()
    except ValueError:  # Duplicated timeseries
        return REGISTRY._names_to_collectors.get(name)

# ×©×™××•×©:
cache_hits = ensure_metric(
    "cache_hits_total",
    lambda: Counter("cache_hits_total", "Total cache hits", ["backend"])
)

request_duration = ensure_metric(
    "request_duration_seconds",
    lambda: Histogram("request_duration_seconds", "Request duration", ["endpoint"])
)

# ×¢×›×©×™×• ××¤×©×¨ ×œ×¢×©×•×ª reload ×œ××•×“×•×œ ×‘×œ×™ ×©×’×™××•×ª
```

---

## ×˜×¢×™× ×ª ×§×•× ×¤×™×’×•×¨×¦×™×” ×¢× Fallback

**×œ××” ×–×” ×©×™××•×©×™:** ×˜×¢×™× ×ª ×”×’×“×¨×•×ª ××§×•×‘×¥ YAML ×‘×‘×˜×—×”. ×× ×”×§×•×‘×¥ ×—×¡×¨ ××• ×¤×’×•× â€“ ××—×–×™×¨ ×¢×¨×›×™ ×‘×¨×™×¨×ª ××—×“×œ ×‘××§×•× ×œ×§×¨×•×¡.

```python
from pathlib import Path

try:
    import yaml
except ImportError:
    yaml = None

def load_config(config_path: str, default: dict = None) -> dict:
    """×˜×¢×™× ×ª ×§×•× ×¤×™×’×•×¨×¦×™×” ×¢× fallback"""
    if default is None:
        default = {}

    if yaml is None:
        return default

    try:
        path = Path(config_path)
        if not path.exists():
            return default

        content = path.read_text(encoding='utf-8')
        data = yaml.safe_load(content) or {}

        # ××™×–×•×’ ×¢× ×‘×¨×™×¨×•×ª ××—×“×œ
        result = dict(default)
        result.update(data)
        return result

    except Exception:
        return default

# ×©×™××•×©:
config = load_config(
    'config/settings.yaml',
    default={
        "max_file_size": 1024 * 1024,
        "allowed_extensions": [".py", ".js"],
        "cache_ttl": 300
    }
)
```
